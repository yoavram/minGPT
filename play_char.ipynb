{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incredible-grave",
   "metadata": {},
   "source": [
    "## Train a character-level GPT on some text data\n",
    "\n",
    "The inputs here are simple text files, which we chop up to individual characters and then train GPT on. So you could say this is a char-transformer instead of a char-rnn. Doesn't quite roll off the tongue as well. In this example we will feed it some Shakespeare, which we'll get it to predict character-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amino-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%d/%m/%Y %H:%M:%S\",\n",
    "        level=logging.INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spare-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "from functools import partial\n",
    "\n",
    "from mingpt.chardataset import CharDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neither-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14/01/2025 17:38:03 - INFO - jax._src.xla_bridge -   Unable to initialize backend 'cuda': \n",
      "14/01/2025 17:38:03 - INFO - jax._src.xla_bridge -   Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "14/01/2025 17:38:03 - INFO - jax._src.xla_bridge -   Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/Users/yoavram/miniforge3/envs/minGPT/bin/../lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file), '/usr/local/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('cpu', [CpuDevice(id=0)], 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.default_backend(), jax.local_devices(), jax.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pacific-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "# you can download this file at https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt\n",
    "text = open('input.txt', 'r').read() \n",
    "train_dataset = CharDataset(text, block_size = 128) # one line of poem is roughly 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjustable-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.model import gpt, loss_fn, GPTConfig\n",
    "\n",
    "rng = jax.random.key(242)\n",
    "gpt_config = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reduced-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_loss_fn = hk.transform(partial(loss_fn, config=gpt_config, is_training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gentle-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "rng, subkey = jax.random.split(rng)\n",
    "tconf = TrainerConfig(max_epochs=2, batch_size=512//2, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, \n",
    "                      final_tokens=2*len(train_dataset)*train_dataset.block_size,\n",
    "                      num_workers=4, rng=subkey)\n",
    "trainer = Trainer(hk_loss_fn, train_dataset, None, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retired-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14/01/2025 17:38:51 - INFO - mingpt.trainer -   number of parameters: 25352192\n"
     ]
    }
   ],
   "source": [
    "params = trainer.init_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5416e512-059d-40f7-adb6-5bec8f3ffdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opening-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 4356: train loss 0.23807. lr 3.000718e-04: 100%|██████████| 4357/4357 [08:48<00:00,  8.24it/s]\n",
      "epoch 2 iter 8713: train loss 0.14488. lr 6.000000e-05: 100%|██████████| 4357/4357 [08:26<00:00,  8.59it/s]\n"
     ]
    }
   ],
   "source": [
    "params, _ = trainer.train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "guided-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, let's sample some character-level Shakespeare\n",
    "from mingpt.utils import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civic-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hk.transform(partial(gpt, config=gpt_config, is_training=False))\n",
    "model = hk.without_apply_rng(model).apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-original",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 593/2000 [03:45<05:28,  4.29it/s]"
     ]
    }
   ],
   "source": [
    "context = \"O God, O God!\"\n",
    "x = jnp.array([train_dataset.stoi[s] for s in context])\n",
    "y = sample(params, model, gpt_config, x, 2000, temperature=1.0, sample=True, top_k=10, progress=True)\n",
    "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "objective-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# well that was fun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:minGPT]",
   "language": "python",
   "name": "conda-env-minGPT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
